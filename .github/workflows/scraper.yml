name: Singapore News Scraper

on:
  schedule:
    # 하루 1번 실행 (한국시간 기준: 오전 8시 5분)
    - cron: '5 23 * * *'  # UTC 기준 (KST 08:05)
  workflow_dispatch:  # 수동 실행 가능
  push:
    paths:
      - 'scripts/**'  # 스크립트 변경 시에도 실행

permissions:
  contents: write
  
jobs:
  scrape-and-send:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'  # pip 캐시 활성화
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
    
    - name: Create data directories
      run: |
        mkdir -p data/scraped
        mkdir -p data/history
    
    - name: Run scraper
      env:
        GOOGLE_GEMINI_API_KEY: ${{ secrets.GOOGLE_GEMINI_API_KEY }}
        GITHUB_EVENT_NAME: ${{ github.event_name }}
        SMTP_USER: ${{ secrets.SMTP_USER }}
        SMTP_PASSWORD: ${{ secrets.SMTP_PASSWORD }}
      run: |
        python scripts/scraper.py
      continue-on-error: true  # 스크래핑 실패해도 계속 진행
    
    - name: Check scraping results
      id: check_results
      run: |
        if [ -f "data/latest.json" ]; then
          echo "scraping_success=true" >> $GITHUB_OUTPUT
        else
          echo "scraping_success=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Send to WhatsApp
      if: steps.check_results.outputs.scraping_success == 'true'
      env:
        GREEN_API_INSTANCE_ID: ${{ secrets.GREEN_API_INSTANCE_ID }}
        GREEN_API_TOKEN: ${{ secrets.GREEN_API_TOKEN }}
      run: |
        # Green API 사용 (Whapi 서비스 중단으로 변경)
        python scripts/send_whatsapp_green.py
      continue-on-error: true  # WhatsApp 전송 실패해도 데이터는 저장
    
    - name: Clean up old data
      run: |
        python scripts/cleanup_old_data.py || echo "Cleanup script not found or failed"
    
    - name: Update history
      if: always()  # 항상 실행
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git remote set-url origin https://x-access-token:${GITHUB_TOKEN}@github.com/${{ github.repository }}.git
        
        # Pull latest changes to avoid conflicts
        git pull origin main --rebase || echo "No remote changes to pull"
        
        git add data/scraped/*.json data/history/*.json data/latest.json || echo "No files to add"
        git commit -m "Update scraping and history data [$(date '+%Y-%m-%d %H:%M:%S')]" || echo "No changes to commit"
        
        # Retry push with pull if needed
        git push || (git pull origin main --rebase && git push)
    
    - name: Create workflow summary
      if: always()
      run: |
        echo "## Workflow Summary 📊" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- **Trigger**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Run Time**: $(date '+%Y-%m-%d %H:%M:%S KST')" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ "${{ steps.check_results.outputs.scraping_success }}" == "true" ]; then
          echo "✅ **Scraping**: Success" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ **Scraping**: Failed" >> $GITHUB_STEP_SUMMARY
        fi
        
        # Check latest.json for more details
        if [ -f "data/latest.json" ]; then
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Latest Data" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          cat data/latest.json >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
        fi