name: Singapore News Scraper

on:
  schedule:
    # 하루 3번 실행 (한국시간 기준: 오전 9시, 오후 1시, 오후 6시)
    - cron: '0 0,4,9 * * *'  # UTC 기준
  workflow_dispatch:  # 수동 실행 가능
  push:
    paths:
      - 'scripts/**'  # 스크립트 변경 시에도 실행

permissions:
  contents: write
  
jobs:
  scrape-and-send:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        pip install requests beautifulsoup4 lxml
        pip install googletrans==4.0.0-rc1 google-generativeai
    
    - name: Create data directories
      run: |
        mkdir -p data/scraped
        mkdir -p data/history
    
    - name: Run scraper
      env:
        GOOGLE_GEMINI_API_KEY: ${{ secrets.GOOGLE_GEMINI_API_KEY }}
      run: |
        python scripts/scraper.py
    
    - name: Send to WhatsApp
      run: |
        python scripts/send_whatsapp.py
    
    - name: Update history
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git remote set-url origin https://x-access-token:${GITHUB_TOKEN}@github.com/${{ github.repository }}.git
        git add data/scraped/*.json data/history/*.json data/latest.json || echo "No files to add"
        git commit -m "Update scraping and history data [$(date '+%Y-%m-%d %H:%M:%S')]" || echo "No changes to commit"
        git push