name: Singapore News Scraper

on:
  schedule:
    # í•˜ë£¨ 1ë²ˆ ì‹¤í–‰ (í•œêµ­ì‹œê°„ ê¸°ì¤€: ì˜¤ì „ 8ì‹œ 5ë¶„)
    - cron: '5 23 * * *'  # UTC ê¸°ì¤€ (KST 08:05)
  workflow_dispatch:  # ìˆ˜ë™ ì‹¤í–‰ ê°€ëŠ¥
  push:
    paths:
      - 'scripts/**'  # ìŠ¤í¬ë¦½íŠ¸ ë³€ê²½ ì‹œì—ë„ ì‹¤í–‰

permissions:
  contents: write
  
jobs:
  scrape-and-send:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'  # pip ìºì‹œ í™œì„±í™”
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
    
    - name: Create data directories
      run: |
        mkdir -p data/scraped
        mkdir -p data/history
    
    - name: Run scraper
      env:
        GOOGLE_GEMINI_API_KEY: ${{ secrets.GOOGLE_GEMINI_API_KEY }}
        GITHUB_EVENT_NAME: ${{ github.event_name }}
        SMTP_USER: ${{ secrets.SMTP_USER }}
        SMTP_PASSWORD: ${{ secrets.SMTP_PASSWORD }}
      run: |
        python scripts/scraper.py
      continue-on-error: true  # ìŠ¤í¬ëž˜í•‘ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
    
    - name: Check scraping results
      id: check_results
      run: |
        if [ -f "data/latest.json" ]; then
          echo "scraping_success=true" >> $GITHUB_OUTPUT
        else
          echo "scraping_success=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Send to WhatsApp
      if: steps.check_results.outputs.scraping_success == 'true'
      env:
        GREEN_API_INSTANCE_ID: ${{ secrets.GREEN_API_INSTANCE_ID }}
        GREEN_API_TOKEN: ${{ secrets.GREEN_API_TOKEN }}
      run: |
        # Green API ì‚¬ìš© (Whapi ì„œë¹„ìŠ¤ ì¤‘ë‹¨ìœ¼ë¡œ ë³€ê²½)
        python scripts/send_whatsapp_green.py
      continue-on-error: true  # WhatsApp ì „ì†¡ ì‹¤íŒ¨í•´ë„ ë°ì´í„°ëŠ” ì €ìž¥
    
    - name: Clean up old data
      run: |
        python scripts/cleanup_old_data.py || echo "Cleanup script not found or failed"
    
    - name: Update history
      if: always()  # í•­ìƒ ì‹¤í–‰
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git remote set-url origin https://x-access-token:${GITHUB_TOKEN}@github.com/${{ github.repository }}.git
        
        # Pull latest changes to avoid conflicts
        git pull origin main --rebase || echo "No remote changes to pull"
        
        git add data/scraped/*.json data/history/*.json data/latest.json || echo "No files to add"
        git commit -m "Update scraping and history data [$(date '+%Y-%m-%d %H:%M:%S')]" || echo "No changes to commit"
        
        # Retry push with pull if needed
        git push || (git pull origin main --rebase && git push)
    
    - name: Create workflow summary
      if: always()
      run: |
        echo "## Workflow Summary ðŸ“Š" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- **Trigger**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Run Time**: $(date '+%Y-%m-%d %H:%M:%S KST')" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ "${{ steps.check_results.outputs.scraping_success }}" == "true" ]; then
          echo "âœ… **Scraping**: Success" >> $GITHUB_STEP_SUMMARY
        else
          echo "âŒ **Scraping**: Failed" >> $GITHUB_STEP_SUMMARY
        fi
        
        # Check latest.json for more details
        if [ -f "data/latest.json" ]; then
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Latest Data" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          cat data/latest.json >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
        fi